{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eef0743b-6a7e-4325-8108-a2ee1d5f6bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "\n",
    "# RAG Creation\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# LLM Inference\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "from pathlib import Path\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4014256-2349-4f17-bfe5-45200109ac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_data = \"C:/Users/jacwallace/Repos/TPRM-Accelerator/training_data/office_s1_e4.txt\"\n",
    "\n",
    "# Extract data from request\n",
    "filePath = request_data\n",
    "\n",
    "\n",
    "# Load document txt\n",
    "with open(filePath) as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c71a649-b3a8-46fa-a0a0-8c2d842c270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=7500,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fecc8acf-c179-4167-9b7d-c2cfaa03f272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 4/4 [00:24<00:00,  6.09s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "texts = text_splitter.create_documents([data])\n",
    "\n",
    "chunks = text_splitter.split_documents(texts)\n",
    "\n",
    "# Add to vector database\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=OllamaEmbeddings(model=\"nomic-embed-text\",show_progress=True),\n",
    "    collection_name=\"local-rag\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9820981e-0da5-435b-b990-7b25a0811a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from request\n",
    "question = \"What is the alliance they speak of in this episode?\"\n",
    "\n",
    "# LLM from Ollama\n",
    "local_model = \"llama2\"\n",
    "llm = ChatOllama(model=local_model)\n",
    "\n",
    "QUERY_PROMPT = PromptTemplate(\n",
    "input_variables = [\"question\"],\n",
    "template = \"\"\"You are an AI language model assistant. Your task is to generate five different versions of \n",
    "the given user question to retrieve relevant documents from vector database. By generating multiple respectives \n",
    "on the user question, your goal is to help the user overcome some of the limitations of the distance-based \n",
    "similarity search. Provide these alternative questions separated by newlines.\n",
    "Original question: {question}\"\"\",\n",
    ")\n",
    "\n",
    "retriever = MultiQueryRetriever.from_llm(\n",
    "vector_db.as_retriever(),\n",
    "llm,\n",
    "prompt = QUERY_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f66c79a3-c9e5-4ba8-959e-b8bf4905f33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# RAG Prompt\n",
    "template = \"\"\"Answer the question based ONLY on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "{\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "| prompt\n",
    "| llm\n",
    "| StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "938e8fc6-6951-45b7-8b86-d4261af62125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.91s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.09s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.14s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.14s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this episode of The Office, the alliance being referred to is the surprise party for Meredith's birthday. Michael has planned a surprise party for Meredith, but Jim and Dwight are also involved in the plan. They want to keep the party a secret from Meredith until the big reveal, so they tape the lid of the box containing the cake shut and try to quiet Jim when he tries to tell Meredith about it. The alliance is the group of people working together to pull off the surprise party without Meredith knowing about it.\n"
     ]
    }
   ],
   "source": [
    "rag_response = chain.invoke((question))\n",
    "print(rag_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d0ffd5-0084-43ea-81ac-e7040e571362",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
