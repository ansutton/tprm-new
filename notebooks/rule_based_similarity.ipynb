{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0b332bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import tensorflow as tf\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import faiss\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d97e23ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing applications document extraction method\n",
    "def _get_page_contents_from_pdf_file_path(pdf_path):\n",
    "    pdf_loader = PyPDFLoader(pdf_path)\n",
    "    raw_documents= pdf_loader.load()\n",
    "    return raw_documents\n",
    "\n",
    "def _get_page_contents_from_pdf_in_memory(pdf_bytes):\n",
    "    # Write bytes to a temporary file\n",
    "    with tempfile.NamedTemporaryFile(delete=False,suffix='.pdf') as temp_pdf_file:\n",
    "        temp_pdf_file.write(pdf_bytes)\n",
    "        temp_pdf_file_path = temp_pdf_file.name\n",
    "    # Load temp file\n",
    "    pdf_loader = PyPDFLoader(temp_pdf_file_path)\n",
    "    raw_documents= pdf_loader.load()\n",
    "    # Delete temporary file\n",
    "    os.remove(temp_pdf_file_path)\n",
    "    return raw_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07722aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_store(pdf_file, from_file_path=True):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=100,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "\n",
    "    if from_file_path:\n",
    "        data = _get_page_contents_from_pdf_file_path(pdf_file)\n",
    "    else:\n",
    "        data = _get_page_contents_from_pdf_in_memory(pdf_file)\n",
    "\n",
    "\n",
    "    documents = text_splitter.split_documents(data)\n",
    "\n",
    "\n",
    "    # Generate embeddings using OllamaEmbeddings\n",
    "    embedding_model = OllamaEmbeddings(model ='nomic-embed-text', show_progress=True)\n",
    "    batch_size = 50\n",
    "    texts=[doc for doc in documents]\n",
    "    documents_embeddings = []\n",
    "\n",
    "\n",
    "    for i in range(0, len(texts),batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        batch_embeddings = embedding_model.embed_documents(batch_texts)\n",
    "        documents_embeddings.extend(batch_embeddings)\n",
    "    \n",
    "    #create FAISS index and add the embeddings\n",
    "    document_embeddings_np = np.array(documents_embeddings)\n",
    "    dimension = document_embeddings_np.shape[1]\n",
    "    faiss_index = faiss.IndexFlatL2(dimension)\n",
    "    faiss_index.add(document_embeddings_np)\n",
    "\n",
    "    docstore = InMemoryDocstore(dict(enumerate(documents)))\n",
    "    index_to_docstore_id = {i: i for i in range(len(documents))}\n",
    "\n",
    "    vector_store = FAISS(embedding_model, faiss_index, docstore, index_to_docstore_id)\n",
    "    \n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c601afe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_relevant_sections(vector_store, question, top_n=50):\n",
    "    \"\"\"Retrieves top-N most relevant sections from the vector store based on a question.\"\"\"\n",
    "    # Load pre-trained nomic model and tokenizer\n",
    "    embedding_model = OllamaEmbeddings(model ='nomic-embed-text', show_progress=True)\n",
    "\n",
    "    question_embedding = embedding_model.embed_query(question)  # Assuming your embedding model has an embed_query method\n",
    "\n",
    "    # Perform similarity search\n",
    "    similar_docs = vector_store.similarity_search_by_vector(question_embedding, k=top_n)\n",
    "\n",
    "    # Extract relevant sections (assuming each document has a 'page_content' attribute)\n",
    "    relevant_sections = [doc.page_content for doc in similar_docs]\n",
    "\n",
    "    return relevant_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "913d71df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_similarity_all(relevant_sections, questions, ai_answers, third_party_answers):\n",
    "    # Use the same OllamaEmbeddings model\n",
    "    embedding_model = OllamaEmbeddings(model='nomic-embed-text', show_progress=True)\n",
    "\n",
    "    similarities = {'ai': [], 'third_party': []}\n",
    "    for question, rel_sections, ai_answer, third_party_answer in zip(questions, relevant_sections, ai_answers, third_party_answers):\n",
    "        # Embed the answers\n",
    "        ai_answer_embedding = embedding_model.embed_query(ai_answer)\n",
    "        third_party_answer_embedding = embedding_model.embed_query(third_party_answer)\n",
    "\n",
    "        max_similarities = {'ai': 0, 'third_party': 0}\n",
    "        for section in rel_sections:\n",
    "            # Embed the relevant section\n",
    "            section_embedding = embedding_model.embed_query(section)\n",
    "\n",
    "            # Calculate semantic similarity\n",
    "            section_embedding_tensor = tf.constant(section_embedding)\n",
    "            ai_answer_embedding_tensor = tf.constant(ai_answer_embedding)\n",
    "            third_party_answer_embedding_tensor = tf.constant(third_party_answer_embedding)\n",
    "\n",
    "            ai_similarity = tf.reduce_sum(section_embedding_tensor * ai_answer_embedding_tensor) / (tf.norm(section_embedding_tensor) * tf.norm(ai_answer_embedding_tensor))\n",
    "            tp_similarity = tf.reduce_sum(section_embedding_tensor * third_party_answer_embedding_tensor) / (tf.norm(section_embedding_tensor) * tf.norm(third_party_answer_embedding_tensor))\n",
    "\n",
    "            max_similarities['ai'] = max(max_similarities['ai'], ai_similarity.numpy())\n",
    "            max_similarities['third_party'] = max(max_similarities['third_party'], tp_similarity.numpy())\n",
    "\n",
    "        similarities['ai'].append(max_similarities['ai'])\n",
    "        similarities['third_party'].append(max_similarities['third_party'])\n",
    "\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1331ebdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_answers = [\"Access control procedures mentioned in the document include:\\n\\n1. On page 60-62 (GCP SOC 2 doc): Customers are responsible for provisioning, maintaining, monitoring, and disabling end users' access according to their internal access management policies. The entity implements logical access security software, infrastructure, and architectures over protected information assets to protect them from security events that meet the entity's objectives. Prior to issuing system credentials and granting system access, the entity registers and authorizes new internal and external users whose access is administered by the entity. For those users whose access is administered by the entity, user system credentials are removed when access is no longer authorized.\\n\\n2. On page 67 (GCP SOC 2 doc): The entity authorizes, modifies, or removes access to data, software, functions, and other protected information assets based on roles. This is done within the customer's environment consistent with customer policies.\\n\\n3. On page 48 (GCP SOC 2 doc): Production system access is granted only to individuals who have completed required security and privacy training and require this level of access to perform tasks. Access to individual production systems via critical access groups is reviewed periodically by the system owners, and inappropriate access is removed for Google personnel who no longer have a business need for it. Access to all corporate and production resources are automatically removed upon submission of a termination request by the manager of any departing employee or by the appropriate Human Resources manager.\\n\\n4. Password guidelines: Google personnel are required to authenticate using valid credentials prior to resetting their passwords. Passwords are managed in accordance with a set of password construction requirements (cited from page 48, but the exact guidelines are not specified in the given context).\",\n",
    "                \"A backup of the data is performed as per the data retention and deletion policies. The process involves the use of data deletion tools that verify the backup data is deleted following the configured retention period, as part of the deletion mechanism process. This information can be found on page 77 of the document: 'was disposed of as per the data retention and deletion policies. No deviations noted. Inspected a sample product and determined data deletion tools verified that backup data was deleted following the configured retention period, as part of the deletion mechanism process. No deviations noted.'\",\n",
    "                \"To ensure that periodic penetration tests are performed for the infrastructure, devices, and end-points, Google has the following measures in place:\\n\\n1. Penetration tests are performed at least annually. (CC4.1)\\n2. The organization performs penetration tests by qualified internal personnel or an external service provider at least annually. (Inquired of the Program Manager)\\n\\nNo deviations were noted in these procedures during the testing process, as confirmed by the results shared by EY after their inspection. \\n\\nReference(s):\\n- Page 54: 'logs is restricted to authorized personnel. Security event logs are monitored continuously using a Google proprietary Security Event Management (SEM) system to detect intrusion attempts and other security related events.'\\n- Page 168: 'Control Description SOC 2 Criteria, Controls, Tests and Results of Tests \\\\n...112. Penetration tests are performed at least annually. CC4.1...'\"]\n",
    "\n",
    "#answers to questions 1, 15, and 17\n",
    "\n",
    "third_party_answers = [\"Google follows a formal process to grant or revoke employee access to Google resources. Access to systems and data is granted only to authorized users. Access requests are reviewed and approved by an authorized second individual prior to being granted and the event is logged. Both user and internal access to customer data are restricted through the use of unique user account IDs and the Google Accounts Bring Your Own Identity (BYOID) system. Access to sensitive systems and applications requires two-factor authentication. Periodic reviews of access lists are implemented to ensure access to customer data is appropriate and authorized. Access to production machines, network devices and support tools is managed via an access group management system. Membership in these groups must be approved by respective group administrators. User group memberships are reviewed on a semiannual basis and any inappropriate access is removed. Access authorization in Google Cloud Platform is enforced at all relevant layers of the system. The granting or modification of access rights is based on the user's job responsibilities or on a need-to-know basis and must be authorized and approved by the user's functional manager or system owners. Access to all corporate and production resources are automatically removed upon submission of a termination request by the manager of any departing employee, or by the appropriate Human Resources manager.\",\n",
    "                \"At Google Cloud Platform, data backup is performed through a robust, automated system that ensures data integrity and availability. We use a combination of incremental and full backups to optimize both storage efficiency and data recovery times. These backups are geographically distributed across multiple secure data centers to provide redundancy and high availability. Additionally, our backup procedures are compliant with industry standards and are regularly audited to ensure they meet stringent security and privacy requirements.\",\n",
    "                \"External third-party penetration tests are performed on an annual basis for a predetermined subset of the services included in the Google Cloud Platform System. The subset of services included in any given year are determined by the Google Security and the Office of Compliance & Integrity teams. This is based on their understanding of the organization's current risk environment, as well as the organization's current regulatory and compliance requirements. Corrective actions are taken as necessary.\"]\n",
    "\n",
    "questions = [\"What access control procedures are in place?\",\n",
    "             \"How is a back up of the data performed?\",\n",
    "             \"What is done to ensure that periodic penetration tests are performed for the infrastructure, devices, and end-points?\"]\n",
    "\n",
    "pdf_path = \"C:/Users/ansutton/Desktop/TPRM/TPRM-Accelerator/assets/data/Security Evidence Docs/SOC 2/GoogleCloud/Audit-Reports-1720774833381-81ba2e/GCP-[FALL-2023] GCP SOC 2..pdf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d449078",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 50/50 [00:30<00:00,  1.63it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 50/50 [00:30<00:00,  1.66it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 50/50 [00:30<00:00,  1.67it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 50/50 [00:28<00:00,  1.73it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 50/50 [00:28<00:00,  1.74it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 50/50 [00:28<00:00,  1.76it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 50/50 [00:28<00:00,  1.74it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 50/50 [00:28<00:00,  1.77it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 50/50 [00:27<00:00,  1.80it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 30/30 [00:18<00:00,  1.60it/s]\n"
     ]
    }
   ],
   "source": [
    "evidence_text = create_vector_store(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04ec90e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 21.46it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 14.44it/s]\n"
     ]
    }
   ],
   "source": [
    "relevant_sections = []\n",
    "for question in questions:\n",
    "    relevant_section = find_relevant_sections(evidence_text, question)\n",
    "    relevant_sections.append(relevant_section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5dfb567a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  1.76it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.82it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.58it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.65it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.47it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.93it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.59it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.49it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.56it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.53it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.49it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.48it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.52it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.64it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.50it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.72it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.37it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.59it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.54it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.33it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.47it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.59it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.28it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.38it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.61it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.59it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.60it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.26it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.85it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.82it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.59it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  3.66it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.73it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.54it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.69it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.56it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.59it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.44it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.48it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.68it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.51it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.89it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.17it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  3.54it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  4.73it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.70it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.27it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  3.19it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.59it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.88it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  3.45it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.69it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.74it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.66it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.82it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.51it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.85it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.83it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.65it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.49it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.66it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.86it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.47it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.38it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.61it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.54it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.48it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.70it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.57it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.75it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.65it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.52it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.66it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  3.27it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.51it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.75it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.67it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.65it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  3.30it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.51it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.61it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.73it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.57it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.76it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.84it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.83it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.64it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.86it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.36it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  4.71it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.55it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.26it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.47it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.51it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.81it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.80it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.73it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.78it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.46it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.58it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.67it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.83it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.70it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.80it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.66it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.13it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.63it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.29it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.58it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.62it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.58it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.48it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.30it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.69it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.69it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.30it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.73it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.54it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.81it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.39it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.50it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.62it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.60it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.55it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.69it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  3.09it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.58it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.37it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.53it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.70it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.52it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  3.56it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.19it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.76it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What access control procedures are in place?\n",
      "  AI Similarity: 0.8381991982460022\n",
      "  Third-party Similarity: 0.9081324934959412\n",
      "---\n",
      "Question: How is a back up of the data performed?\n",
      "  AI Similarity: 0.8988619446754456\n",
      "  Third-party Similarity: 0.8300479650497437\n",
      "---\n",
      "Question: What is done to ensure that periodic penetration tests are performed for the infrastructure, devices, and end-points?\n",
      "  AI Similarity: 0.8731306195259094\n",
      "  Third-party Similarity: 0.905375599861145\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have relevant_sections, questions, ai_answers, and third_party_answers defined\n",
    "semantic_similarities = semantic_similarity_all(relevant_sections, questions, ai_answers, third_party_answers)\n",
    "\n",
    "# Print the results\n",
    "for i, question in enumerate(questions):\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"  AI Similarity: {semantic_similarities['ai'][i]}\")\n",
    "    print(f\"  Third-party Similarity: {semantic_similarities['third_party'][i]}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cab46d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What access control procedures are in place?\n",
      "  AI Similarity: 91.91%\n",
      "  Third-Party Similarity: 95.41%\n",
      "Question: How is a back up of the data performed?\n",
      "  AI Similarity: 94.94%\n",
      "  Third-Party Similarity: 91.50%\n",
      "Question: What is done to ensure that periodic penetration tests are performed for the infrastructure, devices, and end-points?\n",
      "  AI Similarity: 93.66%\n",
      "  Third-Party Similarity: 95.27%\n"
     ]
    }
   ],
   "source": [
    "for i, question in enumerate(questions):\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"  AI Similarity: {((semantic_similarities['ai'][i] + 1) / 2) * 100:.2f}%\")\n",
    "    print(f\"  Third-Party Similarity: {((semantic_similarities['third_party'][i] + 1) / 2) * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
