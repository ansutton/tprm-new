{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import faiss  # type: ignore\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import os\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_multiple_pdf_files(file_paths):\n",
    "    \"\"\"\n",
    "    Load multiple PDF files using PyPDFLoader and extract metadata.\n",
    "\n",
    "    Args:\n",
    "        file_paths (list): List of file paths to PDF files.\n",
    "\n",
    "    Returns:\n",
    "        list: List of Document objects with content and metadata.\n",
    "    \"\"\"\n",
    "    documents_with_metadata = []\n",
    "    for file_path in file_paths:\n",
    "        reader = PdfReader(file_path)\n",
    "        \n",
    "        for page_number, page in enumerate(reader.pages):\n",
    "            content = page.extract_text()\n",
    "            metadata = {\n",
    "                \"title\": reader.metadata.get(\"title\", \"Unknown Title\"),\n",
    "                \"author\": reader.metadata.get(\"author\", \"Unknown Author\"),\n",
    "                \"source\": file_path,\n",
    "                \"page_number\": page_number +1\n",
    "            }\n",
    "        documents_with_metadata.append(Document(page_content=content, metadata=metadata))\n",
    "    \n",
    "    return documents_with_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_documents(raw_documents):\n",
    "    \"\"\"\n",
    "    Split raw documents into chunks using RecursiveCharacterTextSplitter.\n",
    "\n",
    "    Args:\n",
    "        raw_documents (list): List of Document objects.\n",
    "\n",
    "    Returns:\n",
    "        list: List of split Document objects.\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=100,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "    return text_splitter.split_documents(raw_documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Document:\n",
    "#     def __init__(self, text):\n",
    "#         self.text = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def word_level_splitter(raw_documents, words_per_chunk=200):\n",
    "#     \"\"\"\n",
    "#     Split raw documents into chunks based on a specified number of words.\n",
    "\n",
    "#     Args:\n",
    "#         raw_documents (list): List of Document objects.\n",
    "#         words_per_chunk (int): Number of words per chunk.\n",
    "\n",
    "#     Returns:\n",
    "#         list: List of split Document objects.\n",
    "#     \"\"\"\n",
    "#     split_documents = []\n",
    "#     for doc in raw_documents:\n",
    "#         # Split the document text into words\n",
    "#         words = doc.text.split()\n",
    "#         # Create chunks of specified number of words\n",
    "#         for i in range(0, len(words), words_per_chunk):\n",
    "#             chunk = ' '.join(words[i:i + words_per_chunk])\n",
    "#             split_documents.append(Document(text=chunk))\n",
    "#     return split_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_store(documents):\n",
    "    \"\"\"\n",
    "    Create a vector store from the documents.\n",
    "\n",
    "    Args:\n",
    "        documents (list): List of Document objects.\n",
    "\n",
    "    Returns:\n",
    "        FAISS: A FAISS vector store.\n",
    "    \"\"\"\n",
    "    # Generate embeddings using OllamaEmbeddings\n",
    "    embedding_model = OllamaEmbeddings(model='nomic-embed-text', show_progress=True)\n",
    "    batch_size = 50\n",
    "    texts = [doc.page_content for doc in documents]\n",
    "    documents_embeddings = []\n",
    "\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        batch_embeddings = embedding_model.embed_documents(batch_texts)\n",
    "        documents_embeddings.extend(batch_embeddings)\n",
    "\n",
    "\n",
    "    # Create FAISS index and add the embeddings\n",
    "    document_embeddings_np = np.array(documents_embeddings)\n",
    "    dimension = document_embeddings_np.shape[1]\n",
    "    faiss_index = faiss.IndexFlatL2(dimension)\n",
    "    faiss_index.add(document_embeddings_np)\n",
    "\n",
    "    docstore = InMemoryDocstore({i: doc for i, doc in enumerate(documents)})\n",
    "    index_to_docstore_id = {i: i for i in range(len(documents))}\n",
    "\n",
    "    vector_store = FAISS(embedding_model, faiss_index, docstore, index_to_docstore_id)\n",
    "\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "file_paths = [\n",
    "    \"C:/Users/ansutton/Desktop/TPRM/TPRM-Accelerator/assets/data/Security Evidence Docs/SOC 2/GoogleCloud/Audit-Reports-1720774833381-81ba2e/GCP-[FALL-2023] GCP SOC 2..pdf\",\n",
    "    \"C:/Users/ansutton/Desktop/TPRM/TPRM-Accelerator/assets/data/Security Evidence Docs/SOC 2/GoogleCloud/Audit-Reports-1720774833381-81ba2e/APP_SHEET-[SPR-2023] AppSheet SOC 2..pdf\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents and extract metadata\n",
    "raw_documents = load_multiple_pdf_files(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split documents into chunks\n",
    "documents = split_documents(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 7/7 [00:03<00:00,  1.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a vector store from the documents\n",
    "vector_store = create_vector_store(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "Title: Unknown Title\n",
      "Author: Unknown Author\n",
      "Source: C:/Users/ansutton/Desktop/TPRM/TPRM-Accelerator/assets/data/Security Evidence Docs/SOC 2/GoogleCloud/Audit-Reports-1720774833381-81ba2e/GCP-[FALL-2023] GCP SOC 2..pdf\n",
      "Page Number: 203\n",
      "Content: Google LLC | Other Information Provided by Google LLC  201 \n",
      "Other Information Provided by Google LLC  \n",
      " \n",
      "Internal Google Traffic  \n",
      "Connections between...\n",
      "----------------------------------------\n",
      "Document 2:\n",
      "Title: Unknown Title\n",
      "Author: Unknown Author\n",
      "Source: C:/Users/ansutton/Desktop/TPRM/TPRM-Accelerator/assets/data/Security Evidence Docs/SOC 2/GoogleCloud/Audit-Reports-1720774833381-81ba2e/GCP-[FALL-2023] GCP SOC 2..pdf\n",
      "Page Number: 203\n",
      "Content: Service to decrypt it. The encrypted key is not stored alongside the encrypted data.  \n",
      "The wrapping keys needed to decrypt user data are only known to...\n",
      "----------------------------------------\n",
      "Document 3:\n",
      "Title: Unknown Title\n",
      "Author: Unknown Author\n",
      "Source: C:/Users/ansutton/Desktop/TPRM/TPRM-Accelerator/assets/data/Security Evidence Docs/SOC 2/GoogleCloud/Audit-Reports-1720774833381-81ba2e/GCP-[FALL-2023] GCP SOC 2..pdf\n",
      "Page Number: 203\n",
      "Content: Google has a policy stat ing that no loose drive may leave Google data centers unless it has been \n",
      "erased (or destroyed), certified as erased by Googl...\n",
      "----------------------------------------\n",
      "Document 4:\n",
      "Title: Unknown Title\n",
      "Author: Unknown Author\n",
      "Source: C:/Users/ansutton/Desktop/TPRM/TPRM-Accelerator/assets/data/Security Evidence Docs/SOC 2/GoogleCloud/Audit-Reports-1720774833381-81ba2e/GCP-[FALL-2023] GCP SOC 2..pdf\n",
      "Page Number: 203\n",
      "Content: erased by writing zeros to the drive and performing a multiple -step verification process to help \n",
      "ensure the drive contains no data. If the drive can...\n",
      "----------------------------------------\n",
      "Document 5:\n",
      "Title: Unknown Title\n",
      "Author: Unknown Author\n",
      "Source: C:/Users/ansutton/Desktop/TPRM/TPRM-Accelerator/assets/data/Security Evidence Docs/SOC 2/GoogleCloud/Audit-Reports-1720774833381-81ba2e/APP_SHEET-[SPR-2023] AppSheet SOC 2..pdf\n",
      "Page Number: 116\n",
      "Content: Trust Services Criteria, Related Controls and Tests of Controls Relevant to the Security, Availability, and Confidentiality Categories     116 / 116  ...\n",
      "----------------------------------------\n",
      "Document 6:\n",
      "Title: Unknown Title\n",
      "Author: Unknown Author\n",
      "Source: C:/Users/ansutton/Desktop/TPRM/TPRM-Accelerator/assets/data/Security Evidence Docs/SOC 2/GoogleCloud/Audit-Reports-1720774833381-81ba2e/APP_SHEET-[SPR-2023] AppSheet SOC 2..pdf\n",
      "Page Number: 116\n",
      "Content: data to determine that the Company implemented \n",
      "procedures to dispose of confidential information \n",
      "according to the data retention and deletion policy...\n",
      "----------------------------------------\n",
      "Document 7:\n",
      "Title: Unknown Title\n",
      "Author: Unknown Author\n",
      "Source: C:/Users/ansutton/Desktop/TPRM/TPRM-Accelerator/assets/data/Security Evidence Docs/SOC 2/GoogleCloud/Audit-Reports-1720774833381-81ba2e/APP_SHEET-[SPR-2023] AppSheet SOC 2..pdf\n",
      "Page Number: 116\n",
      "Content: disposal, release from Company control, or release for \n",
      "reuse.  No exceptions noted.  \n",
      " rishav.bhattacharya99@gmail.comGoogle Confidental Information...\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(documents):\n",
    "    print(f\"Document {i + 1}:\")\n",
    "    print(f\"Title: {doc.metadata.get('title', 'No Title')}\")\n",
    "    print(f\"Author: {doc.metadata.get('author', 'No Author')}\")\n",
    "    print(f\"Source: {doc.metadata.get('source', 'No Source')}\")\n",
    "    print(f\"Page Number: {doc.metadata.get('page_number', 'No Page Number')}\")\n",
    "    print(f\"Content: {doc.page_content[:150]}...\")  # Print the first 150 characters of the content\n",
    "    print(\"-\" * 40)  # Separator for readability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model = \"llama3.2\" \n",
    "llm = ChatOllama(model=local_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm = llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever = vector_store.as_retriever(search_kwargs={\"k\":3}),\n",
    "    return_source_documents = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(query):\n",
    "    result = qa_chain({\"query\": query})\n",
    "    response = result['result']\n",
    "\n",
    "    source_documents = result['source_documents']\n",
    "    pages = []\n",
    "    citations = []\n",
    "    for doc in source_documents:\n",
    "        source = doc.metadata['source']\n",
    "        pages.append((source,doc.metadata['page_number']))\n",
    "        citations.append((source, doc.metadata['page_number'], doc.page_content))  # Include source in the citation\n",
    "    return {\n",
    "        \"response\": response,\n",
    "        \"pages\": pages,\n",
    "        \"citations\": citations\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What access control procedures are in place?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ansutton\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 11.27it/s]\n"
     ]
    }
   ],
   "source": [
    "structured_answer = get_answer(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the provided context, the following access control procedures are in place:\n",
      "\n",
      "1. Access is restricted to a limited number of individuals and applications.\n",
      "2. All access to/from the Key Management Service (KMS) is controlled by Access Control Lists (ACLs).\n",
      "3. Auditing is enabled to determine whether access is appropriate.\n",
      "\n",
      "Additionally, it's mentioned that Google uses a proprietary system for key rotations, which implies that access control procedures are also in place to manage and rotate keys securely.\n"
     ]
    }
   ],
   "source": [
    "print(structured_answer[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('C:/Users/ansutton/Desktop/TPRM/TPRM-Accelerator/assets/data/Security Evidence Docs/SOC 2/GoogleCloud/Audit-Reports-1720774833381-81ba2e/GCP-[FALL-2023] GCP SOC 2..pdf', 203), ('C:/Users/ansutton/Desktop/TPRM/TPRM-Accelerator/assets/data/Security Evidence Docs/SOC 2/GoogleCloud/Audit-Reports-1720774833381-81ba2e/APP_SHEET-[SPR-2023] AppSheet SOC 2..pdf', 116), ('C:/Users/ansutton/Desktop/TPRM/TPRM-Accelerator/assets/data/Security Evidence Docs/SOC 2/GoogleCloud/Audit-Reports-1720774833381-81ba2e/GCP-[FALL-2023] GCP SOC 2..pdf', 203)]\n"
     ]
    }
   ],
   "source": [
    "print(structured_answer[\"pages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('C:/Users/ansutton/Desktop/TPRM/TPRM-Accelerator/assets/data/Security Evidence Docs/SOC 2/GoogleCloud/Audit-Reports-1720774833381-81ba2e/GCP-[FALL-2023] GCP SOC 2..pdf', 203, 'Service to decrypt it. The encrypted key is not stored alongside the encrypted data.  \\nThe wrapping keys needed to decrypt user data are only known to the Key Management Service. \\nAll access to/from the Key Management Service is controlled by ACLs. Access is restricted to a \\nlimited number of individuals and applications, and auditing is enabled to determine whether \\nacce ss is appropriate.  \\nKey Rotations  \\nGoogle uses a proprietary system to periodically generate and rotate an encryption key used to \\nprotect user data at rest on average at least every 90 days. New wrapped encryption keys are \\ngenerated for each new Google stora ge file (a Google file is defined in Encryption of Data Stored \\nat Google above). The system helps ensure that key rotations are managed appropriately, and \\nthat customer data is not encrypted with a discarded key.  \\nDisk Erase Process  \\nGoogle has a policy stat ing that no loose drive may leave Google data centers unless it has been'), ('C:/Users/ansutton/Desktop/TPRM/TPRM-Accelerator/assets/data/Security Evidence Docs/SOC 2/GoogleCloud/Audit-Reports-1720774833381-81ba2e/APP_SHEET-[SPR-2023] AppSheet SOC 2..pdf', 116, 'Trust Services Criteria, Related Controls and Tests of Controls Relevant to the Security, Availability, and Confidentiality Categories     116 / 116       Confidentiality  \\n \\nTSC \\nReference  Trust Services Criteria and Applicable Control \\nActivities  Service Auditor’s Tests  Results of Tests  \\nC1.2  The entity disposes of confidential information to meet the entity’s objectives related to confidentiality.  \\n  \\n  \\n  \\n  The Company has procedures in place to dispose of \\nconfidential information according to the data retention \\nand deletion policy.  Inspected the Data Destruction Guidelines and User \\nData Retention and Deletion Guidelines to determine \\nthat the Company had procedures in place to dispose \\nof confidential information accordin g to the data \\nretention and deletion policy.  No exceptions noted.  \\nInspected the configuration of the automated deletion \\ntool used to dispose of confidential information and \\ndata to determine that the Company implemented'), ('C:/Users/ansutton/Desktop/TPRM/TPRM-Accelerator/assets/data/Security Evidence Docs/SOC 2/GoogleCloud/Audit-Reports-1720774833381-81ba2e/GCP-[FALL-2023] GCP SOC 2..pdf', 203, 'Google LLC | Other Information Provided by Google LLC  201 \\nOther Information Provided by Google LLC  \\n \\nInternal Google Traffic  \\nConnections between internal Google resources use proprietary services similar to  Remote \\nProcedural Calls (RPC) that provide peer -to-peer authentication similar to Kerberos. All traffic is \\nat least cryptographically authenticated between machines, while some connections, including to \\nand from the Key Management Service, are encrypted u sing AES.  \\nKey Management  \\nGoogle uses a proprietary service to manage the distribution, generation and rotation of \\ncryptographic keys. Files or data structures with user -generated content written by Cloud or App \\nEngine services are encrypted with a key. Thi s key is encrypted by the Key Management Service \\nwith a restricted access control list (ACL) of services allowed to request the Key Management \\nService to decrypt it. The encrypted key is not stored alongside the encrypted data.')]\n"
     ]
    }
   ],
   "source": [
    "print(structured_answer[\"citations\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
